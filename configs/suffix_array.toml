[input]
input_type = "local_files"
file_type = "parquet"

[input.read_arguments]
path = "data/data/lit_Latn/train"
split = "train[:10%]"

[algorithm]
algorithm_name = "suffix_array"
text_column = "text"
seed = 42
batch_size = 10000
merge_strategy = "longest"
length_threshold = 100
google_repo_path = "third_party/deduplicate-text-datasets"
cache_dir = ".cache"

[output]
output_dir = "output"
clean_cache = false
save_clusters = false
keep_index_column = false
keep_cluster_column = false
skip_filtering = false

[debug]
enable_profiling = false
